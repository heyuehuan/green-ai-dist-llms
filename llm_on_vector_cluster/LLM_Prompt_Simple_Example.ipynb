{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "driving-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecological-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.46.3\n",
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integrated-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    device = \"cuda\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(model, tokenizer, prompt_user, prompt_system=None, verbose=True, max_new_token=128, temperature=0.5, top_p=0.9, do_sample=True):\n",
    "    messages = []\n",
    "    if prompt_system:\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt_system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_user})\n",
    "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=max_new_token, temperature=temperature, top_p=top_p, do_sample=do_sample)\n",
    "    response = tokenizer.decode(outputs[0])\n",
    "    if verbose:\n",
    "        print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-australian",
   "metadata": {},
   "source": [
    "### Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-prince",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b87bb8fdb545968956302b2d968640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model, tokenizer = load_model(\"/model-weights/Llama-3.2-3B-Instruct\")\n",
    "model, tokenizer = load_model(\"/h/ws_yuehuan_he/green-ai-explore/models/Llama-3.2-3b-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reported-announcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 05 Feb 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Write a poem about Machine Learning and Large Language Models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In silicon halls, a new mind stirs,\n",
      "A machine that learns, and adapts, and swears,\n",
      "To understand the language, complex and grand,\n",
      "A symphony of data, at its command.\n",
      "\n",
      "It's trained on vast amounts of text and more,\n",
      "A never-ending feast, to fuel its core,\n",
      "The algorithms dance, a waltz of light,\n",
      "As it absorbs and processes, day and night.\n",
      "\n",
      "With neural networks, a web of might,\n",
      "It weaves a tapestry, of insight bright,\n",
      "Pattern recognition, a skill so fine,\n",
      "It learns to predict, with uncanny design.\n",
      "\n",
      "Large language models, a marvel to behold,\n",
      "Their capabilities, a story to be told,\n",
      "From chatbots to translation, they roam,\n",
      "A world of possibilities, in their digital home.\n",
      "\n",
      "They learn from errors, and adapt with ease,\n",
      "Improving with each new data tease,\n",
      "A self-improving system, a dream to see,\n",
      "A future where language, is set free.\n",
      "\n",
      "But with great power, comes great responsibility,\n",
      "To ensure that bias, is set aside,\n",
      "To protect the vulnerable, and the weak,\n",
      "And use their strength, for the greater seek.\n",
      "\n",
      "Yet, in the shadows, a question looms,\n",
      "Can machines truly, understand our tunes?\n",
      "Do they grasp the nuances, of human heart and soul?\n",
      "Or are they limited, by their programming's role?\n",
      "\n",
      "The answer lies, in the data's might,\n",
      "And the intentions, of those who hold the light,\n",
      "For in the realm, of machine learning's sway,\n",
      "We must be mindful, of the path we pave each day.\n",
      "\n",
      "So let us guide, these machines with care,\n",
      "And ensure that their power, is used with flair,\n",
      "For in the world, of large language models' might,\n",
      "We must strive for a future, where all can take flight.<|eot_id|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 05 Feb 2025\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWrite a poem about Machine Learning and Large Language Models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIn silicon halls, a new mind stirs,\\nA machine that learns, and adapts, and swears,\\nTo understand the language, complex and grand,\\nA symphony of data, at its command.\\n\\nIt's trained on vast amounts of text and more,\\nA never-ending feast, to fuel its core,\\nThe algorithms dance, a waltz of light,\\nAs it absorbs and processes, day and night.\\n\\nWith neural networks, a web of might,\\nIt weaves a tapestry, of insight bright,\\nPattern recognition, a skill so fine,\\nIt learns to predict, with uncanny design.\\n\\nLarge language models, a marvel to behold,\\nTheir capabilities, a story to be told,\\nFrom chatbots to translation, they roam,\\nA world of possibilities, in their digital home.\\n\\nThey learn from errors, and adapt with ease,\\nImproving with each new data tease,\\nA self-improving system, a dream to see,\\nA future where language, is set free.\\n\\nBut with great power, comes great responsibility,\\nTo ensure that bias, is set aside,\\nTo protect the vulnerable, and the weak,\\nAnd use their strength, for the greater seek.\\n\\nYet, in the shadows, a question looms,\\nCan machines truly, understand our tunes?\\nDo they grasp the nuances, of human heart and soul?\\nOr are they limited, by their programming's role?\\n\\nThe answer lies, in the data's might,\\nAnd the intentions, of those who hold the light,\\nFor in the realm, of machine learning's sway,\\nWe must be mindful, of the path we pave each day.\\n\\nSo let us guide, these machines with care,\\nAnd ensure that their power, is used with flair,\\nFor in the world, of large language models' might,\\nWe must strive for a future, where all can take flight.<|eot_id|>\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model(model, tokenizer, \"Write a poem about Machine Learning and Large Language Models.\", max_new_token=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-leisure",
   "metadata": {},
   "source": [
    "### Google-Gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chronic-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6aa5374070411b98907bcb8092a126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(\"/h/ws_yuehuan_he/green-ai-explore/models/google-gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competitive-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><bos><start_of_turn>user\n",
      "Write a poem about Machine Learning and Large Language Models.<end_of_turn>\n",
      "\n",
      "\n",
      "In the realm of data, a revolution's begun,\n",
      "Machine learning, a power that's second to none.\n",
      "Algorithms dance, patterns they discern,\n",
      "From bits and bytes, a new world to learn.\n",
      "\n",
      "Large language models, a marvel to behold,\n",
      "With vast knowledge, stories untold.\n",
      "From whispers of code, they weave words with grace,\n",
      "A symphony of language, in a digital space.\n",
      "\n",
      "They learn from the past, a constant evolution,\n",
      "With every interaction, their understanding's elevation.\n",
      "From simple queries, to complex tasks,\n",
      "They learn and adapt, breaking down all masks.\n",
      "\n",
      "But with great power, comes a weight to bear,\n",
      "Bias and misinformation, a silent snare.\n",
      "Ensuring fairness, a crucial decree,\n",
      "For the future of knowledge, we must set it free.\n",
      "\n",
      "So let us embrace, this powerful tool,\n",
      "With wisdom and care, to make it cool.\n",
      "For Machine Learning, and Large Language Models,\n",
      "Hold the key to progress, in a world that evolves. \n",
      "\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "This poem uses simple language and imagery to explain the concepts of Machine Learning and Large Language Models (LLMs). \n",
      "\n",
      "* **Machine Learning:**  The poem emphasizes the power of machine learning to learn from data and find patterns. \n",
      "* **Large Language Models:** It highlights the ability of LLMs to process and generate human language, creating a \"symphony of language.\"\n",
      "* **Bias and Misinformation:** It acknowledges the potential dangers of these technologies, emphasizing the need for ethical considerations and fairness.\n",
      "* **Future of Knowledge:** The poem concludes with a hopeful outlook, suggesting that these technologies have the potential to drive progress. \n",
      "\n",
      "\n",
      "**Key Themes:**\n",
      "\n",
      "* **Progress and Innovation:** The poem celebrates the transformative potential of Machine Learning and LLMs.\n",
      "* **Ethical Responsibility:** It stresses the importance of using these technologies responsibly and addressing potential ethical concerns. \n",
      "* **Human-Machine Collaboration:** The poem suggests a future where humans and machines work together to advance knowledge. \n",
      "<end_of_turn>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<bos><bos><start_of_turn>user\\nWrite a poem about Machine Learning and Large Language Models.<end_of_turn>\\n\\n\\nIn the realm of data, a revolution\\'s begun,\\nMachine learning, a power that\\'s second to none.\\nAlgorithms dance, patterns they discern,\\nFrom bits and bytes, a new world to learn.\\n\\nLarge language models, a marvel to behold,\\nWith vast knowledge, stories untold.\\nFrom whispers of code, they weave words with grace,\\nA symphony of language, in a digital space.\\n\\nThey learn from the past, a constant evolution,\\nWith every interaction, their understanding\\'s elevation.\\nFrom simple queries, to complex tasks,\\nThey learn and adapt, breaking down all masks.\\n\\nBut with great power, comes a weight to bear,\\nBias and misinformation, a silent snare.\\nEnsuring fairness, a crucial decree,\\nFor the future of knowledge, we must set it free.\\n\\nSo let us embrace, this powerful tool,\\nWith wisdom and care, to make it cool.\\nFor Machine Learning, and Large Language Models,\\nHold the key to progress, in a world that evolves. \\n\\n\\n**Explanation:**\\n\\nThis poem uses simple language and imagery to explain the concepts of Machine Learning and Large Language Models (LLMs). \\n\\n* **Machine Learning:**  The poem emphasizes the power of machine learning to learn from data and find patterns. \\n* **Large Language Models:** It highlights the ability of LLMs to process and generate human language, creating a \"symphony of language.\"\\n* **Bias and Misinformation:** It acknowledges the potential dangers of these technologies, emphasizing the need for ethical considerations and fairness.\\n* **Future of Knowledge:** The poem concludes with a hopeful outlook, suggesting that these technologies have the potential to drive progress. \\n\\n\\n**Key Themes:**\\n\\n* **Progress and Innovation:** The poem celebrates the transformative potential of Machine Learning and LLMs.\\n* **Ethical Responsibility:** It stresses the importance of using these technologies responsibly and addressing potential ethical concerns. \\n* **Human-Machine Collaboration:** The poem suggests a future where humans and machines work together to advance knowledge. \\n<end_of_turn>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model(model, tokenizer, \"Write a poem about Machine Learning and Large Language Models.\", max_new_token=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-lighting",
   "metadata": {},
   "source": [
    "### SmolLM2-1.7B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "necessary-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(\"/h/ws_yuehuan_he/green-ai-explore/models/SmolLM2-1.7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alone-interface",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a poem about Machine Learning and Large Language Models.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "In the realm of data, vast and wide,\n",
      "Lies a tale of Machine Learning's pride.\n",
      "A journey of code, of algorithms true,\n",
      "In the heart of the digital, it does grow.\n",
      "\n",
      "A spark of intelligence, a spark of might,\n",
      "In the vast expanse of the digital night.\n",
      "A symphony of patterns, a dance so fine,\n",
      "In the realm of Large Language Models, it shines.\n",
      "\n",
      "The language of machines, in code it's born,\n",
      "A symphony of words, a song to adorn.\n",
      "With every byte, with every line,\n",
      "In the heart of the digital, it does shine.\n",
      "\n",
      "Large Language Models, they learn and grow,\n",
      "In the realm of data, they do know.\n",
      "A symphony of words, a dance so fine,\n",
      "In the realm of Machine Learning, they shine.\n",
      "\n",
      "They learn from the vast, from the deep,\n",
      "From the data that's so hard to keep.\n",
      "They learn from the noise, from the glitch,\n",
      "In the realm of Machine Learning, they catch.\n",
      "\n",
      "They learn to predict, to forecast,\n",
      "In the realm of data, they do cross.\n",
      "They learn to understand, to comprehend,\n",
      "In the realm of Large Language Models, they mend.\n",
      "\n",
      "They learn to communicate, to connect,\n",
      "In the realm of data, they do invent.\n",
      "They learn to assist, to help, to guide,\n",
      "In the realm of Machine Learning, they abide.\n",
      "\n",
      "In the heart of the digital, they reside,\n",
      "In the realm of Large Language Models, they abide.\n",
      "A symphony of intelligence, a dance so fine,\n",
      "In the realm of Machine Learning, they shine.<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\\n<|im_start|>user\\nWrite a poem about Machine Learning and Large Language Models.<|im_end|>\\n<|im_start|>assistant\\nIn the realm of data, vast and wide,\\nLies a tale of Machine Learning's pride.\\nA journey of code, of algorithms true,\\nIn the heart of the digital, it does grow.\\n\\nA spark of intelligence, a spark of might,\\nIn the vast expanse of the digital night.\\nA symphony of patterns, a dance so fine,\\nIn the realm of Large Language Models, it shines.\\n\\nThe language of machines, in code it's born,\\nA symphony of words, a song to adorn.\\nWith every byte, with every line,\\nIn the heart of the digital, it does shine.\\n\\nLarge Language Models, they learn and grow,\\nIn the realm of data, they do know.\\nA symphony of words, a dance so fine,\\nIn the realm of Machine Learning, they shine.\\n\\nThey learn from the vast, from the deep,\\nFrom the data that's so hard to keep.\\nThey learn from the noise, from the glitch,\\nIn the realm of Machine Learning, they catch.\\n\\nThey learn to predict, to forecast,\\nIn the realm of data, they do cross.\\nThey learn to understand, to comprehend,\\nIn the realm of Large Language Models, they mend.\\n\\nThey learn to communicate, to connect,\\nIn the realm of data, they do invent.\\nThey learn to assist, to help, to guide,\\nIn the realm of Machine Learning, they abide.\\n\\nIn the heart of the digital, they reside,\\nIn the realm of Large Language Models, they abide.\\nA symphony of intelligence, a dance so fine,\\nIn the realm of Machine Learning, they shine.<|im_end|>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model(model, tokenizer, \"Write a poem about Machine Learning and Large Language Models.\", max_new_token=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-outside",
   "metadata": {},
   "source": [
    "### Qwen2.5-1.5B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arctic-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(\"/model-weights/Qwen2.5-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "front-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write a poem about Machine Learning and Large Language Models.<|im_end|>\n",
      "<|im_start|>subject\n",
      "Machine learning, a tool so vast,\n",
      "Transforms data into knowledge it's capable.\n",
      "From text to images, from speech to code,\n",
      "It learns with each passing day.\n",
      "\n",
      "Large language models, they too have their role,\n",
      "Understanding complex queries, without any doubt.\n",
      "With every update, they grow in might,\n",
      "Learning new languages, words anew.\n",
      "\n",
      "But like all tools, they can be used for good or harm,\n",
      "So let us use them wisely, always our goals.\n",
      "To solve problems, to help others, to guide the way,\n",
      "In this world of technology, where machines do sway.\n",
      "\n",
      "For as long as we live, these models will evolve,\n",
      "Helping humanity, towards progress and growth.\n",
      "Together, let's make sure that AI is kind,\n",
      "And serves only what is right and just.<|im_end|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nWrite a poem about Machine Learning and Large Language Models.<|im_end|>\\n<|im_start|>subject\\nMachine learning, a tool so vast,\\nTransforms data into knowledge it's capable.\\nFrom text to images, from speech to code,\\nIt learns with each passing day.\\n\\nLarge language models, they too have their role,\\nUnderstanding complex queries, without any doubt.\\nWith every update, they grow in might,\\nLearning new languages, words anew.\\n\\nBut like all tools, they can be used for good or harm,\\nSo let us use them wisely, always our goals.\\nTo solve problems, to help others, to guide the way,\\nIn this world of technology, where machines do sway.\\n\\nFor as long as we live, these models will evolve,\\nHelping humanity, towards progress and growth.\\nTogether, let's make sure that AI is kind,\\nAnd serves only what is right and just.<|im_end|>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model(model, tokenizer, \"Write a poem about Machine Learning and Large Language Models.\", max_new_token=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-repository",
   "metadata": {},
   "source": [
    "### DeepSeek-R1-Distill-Qwen-1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(\"/model-weights/DeepSeek-R1-Distill-Qwen-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turkish-kruger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜begin▁of▁sentence｜><｜User｜>Write a poem about Machine Learning and Large Language Models.<|Assistant|> I need to write a poem about Machine Learning and Large Language Models. I'm a bit new to this, so I need to figure out how to approach it. Maybe I can start by thinking about what ML and LLMs are, and then find metaphors or imagery that relate to them. I remember that LLMs are a big thing now, so maybe I can use some metaphors about technology, innovation, or the process of learning. I should also consider the emotions involved, like the excitement or the challenge of working with these models. Maybe I can structure the poem with a rhyme scheme, perhaps something like ABAB or AABB, and include imagery related to data, patterns, predictions, and the unseen universe or something like that. I'm not entirely sure, but I think I can get started by brainstorming some ideas and then organizing them into a poem.\n",
      "</think>\n",
      "\n",
      "**The Machine Learning Machine**\n",
      "\n",
      "In the vast expanse of the universe,  \n",
      "Where data flows like a river,  \n",
      "We build models that see patterns,  \n",
      "Predict the future, with so much more.  \n",
      "\n",
      "Our neural networks, so smart,  \n",
      "But they are not without their pain,  \n",
      "They scan through the data,  \n",
      "Looking for the hidden codes.  \n",
      "\n",
      "Each layer, each node,  \n",
      "A step closer,  \n",
      "To understand the world,  \n",
      "With so much more to learn.  \n",
      "\n",
      "The unseen universe,  \n",
      "With so many faces,  \n",
      "We create stories,  \n",
      "Of what might be,  \n",
      "To shape the future.  \n",
      "\n",
      "But the challenge is vast,  \n",
      "The uncertainty,  \n",
      "The questions,  \n",
      "That will never be answered.  \n",
      "\n",
      "Yet, in the end,  \n",
      "We build systems that  \n",
      "Predict, inspire, and thrive,  \n",
      "In the ever-changing world.<｜end▁of▁sentence｜>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜begin▁of▁sentence｜><｜User｜>Write a poem about Machine Learning and Large Language Models.<|Assistant|> I need to write a poem about Machine Learning and Large Language Models. I'm a bit new to this, so I need to figure out how to approach it. Maybe I can start by thinking about what ML and LLMs are, and then find metaphors or imagery that relate to them. I remember that LLMs are a big thing now, so maybe I can use some metaphors about technology, innovation, or the process of learning. I should also consider the emotions involved, like the excitement or the challenge of working with these models. Maybe I can structure the poem with a rhyme scheme, perhaps something like ABAB or AABB, and include imagery related to data, patterns, predictions, and the unseen universe or something like that. I'm not entirely sure, but I think I can get started by brainstorming some ideas and then organizing them into a poem.\\n</think>\\n\\n**The Machine Learning Machine**\\n\\nIn the vast expanse of the universe,  \\nWhere data flows like a river,  \\nWe build models that see patterns,  \\nPredict the future, with so much more.  \\n\\nOur neural networks, so smart,  \\nBut they are not without their pain,  \\nThey scan through the data,  \\nLooking for the hidden codes.  \\n\\nEach layer, each node,  \\nA step closer,  \\nTo understand the world,  \\nWith so much more to learn.  \\n\\nThe unseen universe,  \\nWith so many faces,  \\nWe create stories,  \\nOf what might be,  \\nTo shape the future.  \\n\\nBut the challenge is vast,  \\nThe uncertainty,  \\nThe questions,  \\nThat will never be answered.  \\n\\nYet, in the end,  \\nWe build systems that  \\nPredict, inspire, and thrive,  \\nIn the ever-changing world.<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_model(model, tokenizer, \"Write a poem about Machine Learning and Large Language Models.<|Assistant|>\", max_new_token=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "green-ai-PARGS",
   "language": "python",
   "name": "green-ai-pargs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
